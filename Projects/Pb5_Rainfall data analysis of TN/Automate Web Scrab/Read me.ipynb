{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db11cf79-3dfd-4e1a-bb9e-f60af6b524c7",
   "metadata": {},
   "source": [
    "# Automate Rainfall Data Scraper for Tamil Nadu\n",
    "\n",
    "## Overview\n",
    "This Python script automates the process of scraping daily rainfall data from the Tamil Nadu Smart RIMES website. It uses **Selenium** for web interaction and **BeautifulSoup** for parsing HTML content, storing results in a structured **Pandas DataFrame** for further analysis.\n",
    "\n",
    "---\n",
    "\n",
    "## Dependencies\n",
    "- Python 3.x\n",
    "- Selenium\n",
    "- BeautifulSoup4\n",
    "- pandas\n",
    "- datetime\n",
    "\n",
    "### Additional Tools\n",
    "- **Chrome WebDriver**: Ensure you have the correct version compatible with your Chrome browser.\n",
    "\n",
    "---\n",
    "\n",
    "## Setup Instructions\n",
    "1. Install required Python packages:\n",
    "   ```sh\n",
    "   pip install selenium beautifulsoup4 pandas\n",
    "   ```\n",
    "2. Download and set up **ChromeDriver**:\n",
    "   - Place `chromedriver.exe` in your PATH or specify its location in the script.\n",
    "\n",
    "---\n",
    "\n",
    "## Usage Instructions\n",
    "1. Run the script.\n",
    "2. You will be prompted to enter the **start date** and **end date** in the format `dd-mm-yyyy`.\n",
    "3. The script navigates to the website, retrieves rainfall data for each date, and processes it.\n",
    "\n",
    "### Example Input\n",
    "```\n",
    "Enter the Start & End Date as format dd-mm-yyyy:\n",
    "01-01-2024\n",
    "10-01-2024\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Key Functionalities\n",
    "### Date Input Handling\n",
    "- The script validates and formats user-provided dates.\n",
    "- It generates a list of all dates between the start and end date.\n",
    "\n",
    "### Web Scraping with Selenium\n",
    "- Opens the Tamil Nadu Smart RIMES rainfall data page.\n",
    "- Selects the appropriate dropdown option for daily rainfall.\n",
    "- Enters and searches for each date iteratively.\n",
    "\n",
    "### Data Extraction\n",
    "- Uses BeautifulSoup to parse HTML content.\n",
    "- Extracts rainfall data from the `data_table`.\n",
    "\n",
    "### Data Cleaning and Transformation\n",
    "- Cleans and processes table data to a structured DataFrame.\n",
    "- Converts `value` columns to float for analysis.\n",
    "\n",
    "### Handling No Data Cases\n",
    "- If no rainfall data is available, it logs a default entry with `value = 0`.\n",
    "\n",
    "---\n",
    "\n",
    "## Output\n",
    "- All scraped data is stored in the `Search_Rain_Fall_Data` DataFrame.\n",
    "- Optionally, uncomment the provided code to save results to a CSV file:\n",
    "  ```python\n",
    "  Search_Rain_Fall_Data.to_csv('rainfall_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f82d466-edcf-4130-aba5-a11152bf9564",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
