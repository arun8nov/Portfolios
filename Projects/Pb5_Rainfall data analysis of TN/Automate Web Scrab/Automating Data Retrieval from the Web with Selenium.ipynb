{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d725b00a-14e6-4d63-a82f-33f42ccdad9f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Automating Data Retrieval from the Web with Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73b5e42-08c6-4c05-b29d-fcb98007f38d",
   "metadata": {},
   "source": [
    "# Main program "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "31a37f30-412a-44bc-8f30-2b62f322849f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the Start & End Date as format dd-mm-yy\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "<class 'str'> 01-01-2025\n",
      "<class 'str'> 13-01-2025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arunprakash Babu\\AppData\\Local\\Temp\\ipykernel_4612\\1336419519.py:127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  A.loc[B.index] = C\n",
      "C:\\Users\\Arunprakash Babu\\AppData\\Local\\Temp\\ipykernel_4612\\1336419519.py:153: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  Search_Rain_Fall_Data = pd.concat([Search_Rain_Fall_Data,df3])\n",
      "C:\\Users\\Arunprakash Babu\\AppData\\Local\\Temp\\ipykernel_4612\\1336419519.py:127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  A.loc[B.index] = C\n",
      "C:\\Users\\Arunprakash Babu\\AppData\\Local\\Temp\\ipykernel_4612\\1336419519.py:127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  A.loc[B.index] = C\n",
      "C:\\Users\\Arunprakash Babu\\AppData\\Local\\Temp\\ipykernel_4612\\1336419519.py:127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  A.loc[B.index] = C\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dept</th>\n",
       "      <th>dist</th>\n",
       "      <th>station</th>\n",
       "      <th>value</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Revenue</td>\n",
       "      <td>Kanniyakumari</td>\n",
       "      <td>Suralacode</td>\n",
       "      <td>31.4</td>\n",
       "      <td>2025-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Revenue</td>\n",
       "      <td>Kanniyakumari</td>\n",
       "      <td>Aralvaimozhi</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2025-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Revenue</td>\n",
       "      <td>Nagapattinam</td>\n",
       "      <td>Vedaranyam</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2025-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Revenue</td>\n",
       "      <td>Nagapattinam</td>\n",
       "      <td>Kodiayakarai</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2025-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Revenue</td>\n",
       "      <td>Ramanathapuram</td>\n",
       "      <td>Thangachimadam</td>\n",
       "      <td>24.4</td>\n",
       "      <td>2025-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>Revenue</td>\n",
       "      <td>Tiruvallur</td>\n",
       "      <td>Thamaraipakkam</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2025-01-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>Revenue</td>\n",
       "      <td>Tiruvallur</td>\n",
       "      <td>Tiruvallur</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2025-01-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>Revenue</td>\n",
       "      <td>Villupuram</td>\n",
       "      <td>RSCL-2 Koliyanur</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2025-01-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>Revenue</td>\n",
       "      <td>Villupuram</td>\n",
       "      <td>RSCL-2 Valavanur</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2025-01-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>Revenue</td>\n",
       "      <td>Villupuram</td>\n",
       "      <td>Marakkanam</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2025-01-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>228 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        dept            dist           station  value       date\n",
       "id                                                              \n",
       "0    Revenue   Kanniyakumari        Suralacode   31.4 2025-01-01\n",
       "1    Revenue   Kanniyakumari      Aralvaimozhi    2.0 2025-01-01\n",
       "2    Revenue    Nagapattinam        Vedaranyam    3.8 2025-01-01\n",
       "3    Revenue    Nagapattinam      Kodiayakarai    2.6 2025-01-01\n",
       "4    Revenue  Ramanathapuram    Thangachimadam   24.4 2025-01-01\n",
       "..       ...             ...               ...    ...        ...\n",
       "223  Revenue      Tiruvallur    Thamaraipakkam    3.0 2025-01-13\n",
       "224  Revenue      Tiruvallur        Tiruvallur    3.0 2025-01-13\n",
       "225  Revenue      Villupuram  RSCL-2 Koliyanur    3.0 2025-01-13\n",
       "226  Revenue      Villupuram  RSCL-2 Valavanur    3.0 2025-01-13\n",
       "227  Revenue      Villupuram        Marakkanam    3.0 2025-01-13\n",
       "\n",
       "[228 rows x 5 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Packages\n",
    "\n",
    "import time \n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Create Empty DataFrame to store the values\n",
    "\n",
    "column_Name = ['dept', 'dist', 'station', 'value', 'date']\n",
    "Search_Rain_Fall_Data = pd.DataFrame(columns=column_Name,)\n",
    "Search_Rain_Fall_Data.index.name = 'id'\n",
    "\n",
    "# Get date input\n",
    "\n",
    "print(\"Enter the Start & End Date as format dd-mm-yy\")\n",
    "Start_Date = input(str)\n",
    "End_Date = input(str)\n",
    "\n",
    "# Change date format\n",
    "sd = datetime.strptime(Start_Date,\"%d-%m-%Y\").date()\n",
    "ed = datetime.strptime(End_Date,\"%d-%m-%Y\").date()\n",
    "\n",
    "# Get all list of date between start date and end date\n",
    "\n",
    "List_date_format = [] \n",
    "while sd <= ed:\n",
    "    List_date_format.append(sd)\n",
    "    sd = sd+timedelta(days = 1)\n",
    "    \n",
    "# Change into object method\n",
    "\n",
    "List_Object_format = []\n",
    "for i in range(len(List_date_format)):\n",
    "    List_Object_format.append(List_date_format[i].strftime(\"%d-%m-%Y\"))\n",
    "\n",
    "\n",
    "# Open the browser and enter the site \n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://beta-tnsmart.rimes.int/index.php/Rainfall/daily_data\")\n",
    "\n",
    "# Get the html code from the web and looping over the date\n",
    "\n",
    "for i in List_Object_format:  \n",
    "    # Drop down Selection \n",
    "    dropdown = driver.find_element(By.ID, \"type\")\n",
    "    select = Select(dropdown)\n",
    "    select.select_by_index(1)\n",
    "\n",
    "    Date = i\n",
    "    # Date selection\n",
    "    date = driver.find_element(By.ID, \"date\")\n",
    "    date.clear()\n",
    "    date.send_keys(Date)\n",
    "    \n",
    "    #search the selection\n",
    "    #search = driver.find_element(By.XPATH, '//*[@id=\"submit\"]')\n",
    "    search = driver.find_element(By.NAME,\"submit\")\n",
    "    search.click()\n",
    "        \n",
    "    #Get HTML code & Save as a file\n",
    "    \n",
    "    html_code = driver.page_source\n",
    "    \n",
    "    \n",
    "    # Date find in the html code\n",
    "    \n",
    "    \n",
    "    soup = BeautifulSoup(html_code, 'html')\n",
    "    Da = soup.find(class_ = \"panel-heading\")\n",
    "    \n",
    "    if Da != None:\n",
    "        \n",
    "        # Read the date from html code and tranform into required format\n",
    "        \n",
    "        Da = Da.text.strip().replace(\"District wise observed Rainfall\\n                    data on \",\"\")\n",
    "        month = { \"Jan\" : \"01\", \"Feb\" : \"02\", \"Mar\" : \"03\", \"Apr\" : \"04\", \"May\" : \"05\", \"Jun\" : \"06\", \"Jul\" : \"07\",\n",
    "                  \"Aug\" : \"08\", \"Sep\" : \"09\", \"Oct\" : \"10\", \"Nov\" : \"11\", \"Dec\" : \"12\"}\n",
    "        Date = Da.replace(Da[3:6],month[Da[3:6]])\n",
    "        \n",
    "        # Find table content in html and transform into DataFrame then proceed it to required format\n",
    "        \n",
    "        table = soup.find('table', id = \"data_table\")\n",
    "        table_tr = table.find_all('tr')\n",
    "        list = [table_tr.text.strip().replace(\"\\n\\n\", \",\") for table_tr in table_tr][1:]\n",
    "        datalist = []\n",
    "        for i in range(len(list)):\n",
    "            datalist.append(list[i].strip().replace(\"\\n\",\",\"))\n",
    "        df = pd.DataFrame(datalist, columns = ['A'])\n",
    "        df1 = pd.DataFrame(df)\n",
    "        df1 = df1.A.str.split(\",\",expand = True)\n",
    "        \n",
    "        df1 = df1.drop([len(df)-1])\n",
    "        for i in df1.columns : \n",
    "            if df1[i].isna().sum() == len(df1):\n",
    "                df1 = df1.drop(columns= [i])\n",
    "            else:\n",
    "                df1 = df1  \n",
    "        delete_rows = df1[df1[4].isna()].index\n",
    "        delete_rows = delete_rows.append(df1[-1:].index)\n",
    "        df1 = df1.drop(delete_rows,axis=0)\n",
    "        if len(df1.columns) > 6:\n",
    "            A = df1[[3]]\n",
    "            B = df1[4].str.extract('([a-zA-Z]+)').dropna()\n",
    "            C = df1[5].str.extract('([a-zA-Z]+)').dropna()\n",
    "            B.loc[C.index] = B.loc[C.index] +\",\"+ C.loc[C.index]\n",
    "            D = pd.DataFrame(A.loc[B.index].values + \",\"+ B.values)\n",
    "            D.index = A.loc[B.index].index\n",
    "            A.loc[B.index] = D.copy()\n",
    "            df1[3] = A[3]\n",
    "            E = df1[4].str.extract(r'(\\d+\\.?\\d*)').dropna()\n",
    "            F = df1[5].str.extract(r'(\\d+\\.?\\d*)').dropna()\n",
    "            G = df1[6].str.extract(r'(\\d+\\.?\\d*)').dropna()\n",
    "            H = pd.concat([E,F,G])\n",
    "            df1[[4]] = H\n",
    "        else:\n",
    "            if len(df1.columns) >5:\n",
    "                A = df1[[3]]\n",
    "                B = df1[4].str.extract('([a-zA-Z]+)').dropna()\n",
    "                C = pd.DataFrame(A.loc[B.index].values + \",\"+ B.values,index=B.index)\n",
    "                A.loc[B.index] = C\n",
    "                df1[3] = A[3]\n",
    "                E = df1[4].str.extract(r'(\\d+\\.?\\d*)').dropna()\n",
    "                F = df1[5].str.extract(r'(\\d+\\.?\\d*)').dropna()\n",
    "                H = pd.concat([E,F])\n",
    "                df1[[4]] = H\n",
    "        for i in df1.columns :\n",
    "            if len(df1.columns) !=5 :\n",
    "                df1 = df1.drop(columns= [len(df1.columns)-1])\n",
    "        df1 = df1.drop(columns = [0])\n",
    "\n",
    "        \n",
    "        column_Name = ['dept', 'dist', 'station', 'value']\n",
    "        df1.columns = column_Name\n",
    "        df1.value = df1.value.astype(float)\n",
    "        df1 = df1.reset_index()\n",
    "        df1 = df1.drop(columns = 'index')\n",
    "        \n",
    "        # Add date to every rows\n",
    "        \n",
    "        DL = [Date] \n",
    "        for i in range (len(df1)):\n",
    "            DL.append(DL[0])\n",
    "        C_Date = pd.DataFrame(DL,columns= ['date'])\n",
    "        C_Date.date = pd.to_datetime(C_Date.date, format = \"%d-%m-%Y\")\n",
    "        df3 = df1.join(C_Date)\n",
    "        Search_Rain_Fall_Data = pd.concat([Search_Rain_Fall_Data,df3])\n",
    "    else: \n",
    "        # No rainfall occured in the search\n",
    "        # create empty DF with the date \n",
    "        E = {\n",
    "            'dept' : 'All',\n",
    "            'dist' : 'All',\n",
    "            'station' : 'All',\n",
    "            'value' : 0,\n",
    "            'date' : Date\n",
    "        }\n",
    "        df2 = pd.DataFrame(pd.Series(E)).T\n",
    "        df2.value = df2.value.astype(float)\n",
    "        df2.date = pd.to_datetime(df2.date,format = \"%d-%m-%Y\")\n",
    "        df2.index.name = 'id'\n",
    "        df3 = df2\n",
    "        Search_Rain_Fall_Data = pd.concat([Search_Rain_Fall_Data,df3])\n",
    "    #df3 = pd.read_csv(r\"C:\\Users\\Arunprakash Babu\\OneDrive\\ドキュメント\\GitHub\\Portfolios\\Projects\\Pb5_Rainfall data analysis of TN\\2024_Data.csv\",index_col=0)\n",
    "    #df4 = pd.concat([df3,Search_Rain_Fall_Data ])\n",
    "    #df4.to_csv(r\"C:\\Users\\Arunprakash Babu\\OneDrive\\ドキュメント\\GitHub\\Portfolios\\Projects\\Pb5_Rainfall data analysis of TN\\2024_Data.csv\")\n",
    "driver.quit()  \n",
    "Search_Rain_Fall_Data = Search_Rain_Fall_Data.reset_index(drop=True)\n",
    "Search_Rain_Fall_Data.index.name = 'id'\n",
    "Search_Rain_Fall_Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c89d28b6-20bf-4a3d-9b48-84ea39be70cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\Arunprakash Babu\\OneDrive\\ドキュメント\\GitHub\\Portfolios\\Projects\\Pb5_Rainfall data analysis of TN\\Total_RainFall_Data.csv\",index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a8480044-92a6-423b-a4a7-3b9592f486ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.date = pd.to_datetime(df.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "019b41a7-6ad4-45dd-a727-0f940e41d547",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df,Search_Rain_Fall_Data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b7b9da97-6107-4326-9eb0-29b9d58189e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9a2ce56d-0574-468d-983c-a6992579cccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.name = 'id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2babb1bc-7a65-4afd-a4de-39e927f2ceaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dept</th>\n",
       "      <th>dist</th>\n",
       "      <th>station</th>\n",
       "      <th>value</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Revenue</td>\n",
       "      <td>The Nilgiris</td>\n",
       "      <td>Devala</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1990-02-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Revenue</td>\n",
       "      <td>Coimbatore</td>\n",
       "      <td>Taluk Office, Pollachi</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1990-10-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Revenue</td>\n",
       "      <td>Coimbatore</td>\n",
       "      <td>Taluk Office, Pollachi</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1990-10-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Revenue</td>\n",
       "      <td>Mayiladuthurai</td>\n",
       "      <td>Anaikaranchatram (Kollidam)</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1990-10-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Revenue</td>\n",
       "      <td>Mayiladuthurai</td>\n",
       "      <td>Sirkali</td>\n",
       "      <td>12.4</td>\n",
       "      <td>1990-10-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671952</th>\n",
       "      <td>Revenue</td>\n",
       "      <td>Tiruvallur</td>\n",
       "      <td>Thamaraipakkam</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2025-01-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671953</th>\n",
       "      <td>Revenue</td>\n",
       "      <td>Tiruvallur</td>\n",
       "      <td>Tiruvallur</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2025-01-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671954</th>\n",
       "      <td>Revenue</td>\n",
       "      <td>Villupuram</td>\n",
       "      <td>RSCL-2 Koliyanur</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2025-01-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671955</th>\n",
       "      <td>Revenue</td>\n",
       "      <td>Villupuram</td>\n",
       "      <td>RSCL-2 Valavanur</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2025-01-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671956</th>\n",
       "      <td>Revenue</td>\n",
       "      <td>Villupuram</td>\n",
       "      <td>Marakkanam</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2025-01-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>671957 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           dept            dist                      station  value       date\n",
       "id                                                                            \n",
       "0       Revenue    The Nilgiris                       Devala    5.0 1990-02-13\n",
       "1       Revenue      Coimbatore       Taluk Office, Pollachi    8.0 1990-10-17\n",
       "2       Revenue      Coimbatore       Taluk Office, Pollachi   34.0 1990-10-18\n",
       "3       Revenue  Mayiladuthurai  Anaikaranchatram (Kollidam)   13.0 1990-10-18\n",
       "4       Revenue  Mayiladuthurai                      Sirkali   12.4 1990-10-18\n",
       "...         ...             ...                          ...    ...        ...\n",
       "671952  Revenue      Tiruvallur               Thamaraipakkam    3.0 2025-01-13\n",
       "671953  Revenue      Tiruvallur                   Tiruvallur    3.0 2025-01-13\n",
       "671954  Revenue      Villupuram             RSCL-2 Koliyanur    3.0 2025-01-13\n",
       "671955  Revenue      Villupuram             RSCL-2 Valavanur    3.0 2025-01-13\n",
       "671956  Revenue      Villupuram                   Marakkanam    3.0 2025-01-13\n",
       "\n",
       "[671957 rows x 5 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "85f6d3e1-24f4-4480-b118-9729c5d48dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r\"C:\\Users\\Arunprakash Babu\\OneDrive\\ドキュメント\\GitHub\\Portfolios\\Projects\\Pb5_Rainfall data analysis of TN\\Total_RainFall_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47e09ca-9518-464f-884c-4677a10e5565",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
