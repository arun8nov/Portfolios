{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d725b00a-14e6-4d63-a82f-33f42ccdad9f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Automating Data Retrieval from the Web with Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73b5e42-08c6-4c05-b29d-fcb98007f38d",
   "metadata": {},
   "source": [
    "# Main program "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31a37f30-412a-44bc-8f30-2b62f322849f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the Start & End Date as format dd-mm-yy\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "<class 'str'> 01-01-2024\n",
      "<class 'str'> 10-01-2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arunprakash Babu\\AppData\\Local\\Temp\\ipykernel_11260\\1336419519.py:153: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  Search_Rain_Fall_Data = pd.concat([Search_Rain_Fall_Data,df3])\n",
      "C:\\Users\\Arunprakash Babu\\AppData\\Local\\Temp\\ipykernel_11260\\1336419519.py:127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  A.loc[B.index] = C\n",
      "C:\\Users\\Arunprakash Babu\\AppData\\Local\\Temp\\ipykernel_11260\\1336419519.py:115: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  A.loc[B.index] = D.copy()\n",
      "C:\\Users\\Arunprakash Babu\\AppData\\Local\\Temp\\ipykernel_11260\\1336419519.py:127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  A.loc[B.index] = C\n",
      "C:\\Users\\Arunprakash Babu\\AppData\\Local\\Temp\\ipykernel_11260\\1336419519.py:127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  A.loc[B.index] = C\n",
      "C:\\Users\\Arunprakash Babu\\AppData\\Local\\Temp\\ipykernel_11260\\1336419519.py:127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  A.loc[B.index] = C\n",
      "C:\\Users\\Arunprakash Babu\\AppData\\Local\\Temp\\ipykernel_11260\\1336419519.py:115: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  A.loc[B.index] = D.copy()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dept</th>\n",
       "      <th>dist</th>\n",
       "      <th>station</th>\n",
       "      <th>value</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Revenue</td>\n",
       "      <td>Tenkasi</td>\n",
       "      <td>Gadana dam Section</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2024-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Revenue</td>\n",
       "      <td>Tenkasi</td>\n",
       "      <td>Karuppanadhi Dam section</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2024-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Revenue</td>\n",
       "      <td>Tirunelveli</td>\n",
       "      <td>Oothu</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2024-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Revenue</td>\n",
       "      <td>Tirunelveli</td>\n",
       "      <td>Nalumukku</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2024-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Revenue</td>\n",
       "      <td>Tirunelveli</td>\n",
       "      <td>Manjolai</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2024-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>Revenue</td>\n",
       "      <td>Virudhunagar</td>\n",
       "      <td>Virudhunagar</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2024-01-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>Revenue</td>\n",
       "      <td>Virudhunagar</td>\n",
       "      <td>Sivakasi RDO office</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2024-01-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>Revenue</td>\n",
       "      <td>Virudhunagar</td>\n",
       "      <td>Rajapalayam</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2024-01-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>Revenue</td>\n",
       "      <td>Virudhunagar</td>\n",
       "      <td>Kariyapatti</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2024-01-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545</th>\n",
       "      <td>Revenue</td>\n",
       "      <td>Virudhunagar</td>\n",
       "      <td>Vembakottai Dam</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2024-01-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1546 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         dept          dist                   station  value       date\n",
       "id                                                                     \n",
       "0     Revenue       Tenkasi        Gadana dam Section    6.0 2024-01-01\n",
       "1     Revenue       Tenkasi  Karuppanadhi Dam section    4.0 2024-01-01\n",
       "2     Revenue   Tirunelveli                     Oothu   15.0 2024-01-01\n",
       "3     Revenue   Tirunelveli                 Nalumukku   12.0 2024-01-01\n",
       "4     Revenue   Tirunelveli                  Manjolai   10.0 2024-01-01\n",
       "...       ...           ...                       ...    ...        ...\n",
       "1541  Revenue  Virudhunagar              Virudhunagar    7.0 2024-01-10\n",
       "1542  Revenue  Virudhunagar       Sivakasi RDO office    6.0 2024-01-10\n",
       "1543  Revenue  Virudhunagar               Rajapalayam    5.0 2024-01-10\n",
       "1544  Revenue  Virudhunagar               Kariyapatti    5.0 2024-01-10\n",
       "1545  Revenue  Virudhunagar           Vembakottai Dam    2.0 2024-01-10\n",
       "\n",
       "[1546 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Packages\n",
    "\n",
    "import time \n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Create Empty DataFrame to store the values\n",
    "\n",
    "column_Name = ['dept', 'dist', 'station', 'value', 'date']\n",
    "Search_Rain_Fall_Data = pd.DataFrame(columns=column_Name,)\n",
    "Search_Rain_Fall_Data.index.name = 'id'\n",
    "\n",
    "# Get date input\n",
    "\n",
    "print(\"Enter the Start & End Date as format dd-mm-yy\")\n",
    "Start_Date = input(str)\n",
    "End_Date = input(str)\n",
    "\n",
    "# Change date format\n",
    "sd = datetime.strptime(Start_Date,\"%d-%m-%Y\").date()\n",
    "ed = datetime.strptime(End_Date,\"%d-%m-%Y\").date()\n",
    "\n",
    "# Get all list of date between start date and end date\n",
    "\n",
    "List_date_format = [] \n",
    "while sd <= ed:\n",
    "    List_date_format.append(sd)\n",
    "    sd = sd+timedelta(days = 1)\n",
    "    \n",
    "# Change into object method\n",
    "\n",
    "List_Object_format = []\n",
    "for i in range(len(List_date_format)):\n",
    "    List_Object_format.append(List_date_format[i].strftime(\"%d-%m-%Y\"))\n",
    "\n",
    "\n",
    "# Open the browser and enter the site \n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://beta-tnsmart.rimes.int/index.php/Rainfall/daily_data\")\n",
    "\n",
    "# Get the html code from the web and looping over the date\n",
    "\n",
    "for i in List_Object_format:  \n",
    "    # Drop down Selection \n",
    "    dropdown = driver.find_element(By.ID, \"type\")\n",
    "    select = Select(dropdown)\n",
    "    select.select_by_index(1)\n",
    "\n",
    "    Date = i\n",
    "    # Date selection\n",
    "    date = driver.find_element(By.ID, \"date\")\n",
    "    date.clear()\n",
    "    date.send_keys(Date)\n",
    "    \n",
    "    #search the selection\n",
    "    #search = driver.find_element(By.XPATH, '//*[@id=\"submit\"]')\n",
    "    search = driver.find_element(By.NAME,\"submit\")\n",
    "    search.click()\n",
    "        \n",
    "    #Get HTML code & Save as a file\n",
    "    \n",
    "    html_code = driver.page_source\n",
    "    \n",
    "    \n",
    "    # Date find in the html code\n",
    "    \n",
    "    \n",
    "    soup = BeautifulSoup(html_code, 'html')\n",
    "    Da = soup.find(class_ = \"panel-heading\")\n",
    "    \n",
    "    if Da != None:\n",
    "        \n",
    "        # Read the date from html code and tranform into required format\n",
    "        \n",
    "        Da = Da.text.strip().replace(\"District wise observed Rainfall\\n                    data on \",\"\")\n",
    "        month = { \"Jan\" : \"01\", \"Feb\" : \"02\", \"Mar\" : \"03\", \"Apr\" : \"04\", \"May\" : \"05\", \"Jun\" : \"06\", \"Jul\" : \"07\",\n",
    "                  \"Aug\" : \"08\", \"Sep\" : \"09\", \"Oct\" : \"10\", \"Nov\" : \"11\", \"Dec\" : \"12\"}\n",
    "        Date = Da.replace(Da[3:6],month[Da[3:6]])\n",
    "        \n",
    "        # Find table content in html and transform into DataFrame then proceed it to required format\n",
    "        \n",
    "        table = soup.find('table', id = \"data_table\")\n",
    "        table_tr = table.find_all('tr')\n",
    "        list = [table_tr.text.strip().replace(\"\\n\\n\", \",\") for table_tr in table_tr][1:]\n",
    "        datalist = []\n",
    "        for i in range(len(list)):\n",
    "            datalist.append(list[i].strip().replace(\"\\n\",\",\"))\n",
    "        df = pd.DataFrame(datalist, columns = ['A'])\n",
    "        df1 = pd.DataFrame(df)\n",
    "        df1 = df1.A.str.split(\",\",expand = True)\n",
    "        \n",
    "        df1 = df1.drop([len(df)-1])\n",
    "        for i in df1.columns : \n",
    "            if df1[i].isna().sum() == len(df1):\n",
    "                df1 = df1.drop(columns= [i])\n",
    "            else:\n",
    "                df1 = df1  \n",
    "        delete_rows = df1[df1[4].isna()].index\n",
    "        delete_rows = delete_rows.append(df1[-1:].index)\n",
    "        df1 = df1.drop(delete_rows,axis=0)\n",
    "        if len(df1.columns) > 6:\n",
    "            A = df1[[3]]\n",
    "            B = df1[4].str.extract('([a-zA-Z]+)').dropna()\n",
    "            C = df1[5].str.extract('([a-zA-Z]+)').dropna()\n",
    "            B.loc[C.index] = B.loc[C.index] +\",\"+ C.loc[C.index]\n",
    "            D = pd.DataFrame(A.loc[B.index].values + \",\"+ B.values)\n",
    "            D.index = A.loc[B.index].index\n",
    "            A.loc[B.index] = D.copy()\n",
    "            df1[3] = A[3]\n",
    "            E = df1[4].str.extract(r'(\\d+\\.?\\d*)').dropna()\n",
    "            F = df1[5].str.extract(r'(\\d+\\.?\\d*)').dropna()\n",
    "            G = df1[6].str.extract(r'(\\d+\\.?\\d*)').dropna()\n",
    "            H = pd.concat([E,F,G])\n",
    "            df1[[4]] = H\n",
    "        else:\n",
    "            if len(df1.columns) >5:\n",
    "                A = df1[[3]]\n",
    "                B = df1[4].str.extract('([a-zA-Z]+)').dropna()\n",
    "                C = pd.DataFrame(A.loc[B.index].values + \",\"+ B.values,index=B.index)\n",
    "                A.loc[B.index] = C\n",
    "                df1[3] = A[3]\n",
    "                E = df1[4].str.extract(r'(\\d+\\.?\\d*)').dropna()\n",
    "                F = df1[5].str.extract(r'(\\d+\\.?\\d*)').dropna()\n",
    "                H = pd.concat([E,F])\n",
    "                df1[[4]] = H\n",
    "        for i in df1.columns :\n",
    "            if len(df1.columns) !=5 :\n",
    "                df1 = df1.drop(columns= [len(df1.columns)-1])\n",
    "        df1 = df1.drop(columns = [0])\n",
    "\n",
    "        \n",
    "        column_Name = ['dept', 'dist', 'station', 'value']\n",
    "        df1.columns = column_Name\n",
    "        df1.value = df1.value.astype(float)\n",
    "        df1 = df1.reset_index()\n",
    "        df1 = df1.drop(columns = 'index')\n",
    "        \n",
    "        # Add date to every rows\n",
    "        \n",
    "        DL = [Date] \n",
    "        for i in range (len(df1)):\n",
    "            DL.append(DL[0])\n",
    "        C_Date = pd.DataFrame(DL,columns= ['date'])\n",
    "        C_Date.date = pd.to_datetime(C_Date.date, format = \"%d-%m-%Y\")\n",
    "        df3 = df1.join(C_Date)\n",
    "        Search_Rain_Fall_Data = pd.concat([Search_Rain_Fall_Data,df3])\n",
    "    else: \n",
    "        # No rainfall occured in the search\n",
    "        # create empty DF with the date \n",
    "        E = {\n",
    "            'dept' : 'All',\n",
    "            'dist' : 'All',\n",
    "            'station' : 'All',\n",
    "            'value' : 0,\n",
    "            'date' : Date\n",
    "        }\n",
    "        df2 = pd.DataFrame(pd.Series(E)).T\n",
    "        df2.value = df2.value.astype(float)\n",
    "        df2.date = pd.to_datetime(df2.date,format = \"%d-%m-%Y\")\n",
    "        df2.index.name = 'id'\n",
    "        df3 = df2\n",
    "        Search_Rain_Fall_Data = pd.concat([Search_Rain_Fall_Data,df3])\n",
    "    #df3 = pd.read_csv(r\"C:\\Users\\Arunprakash Babu\\OneDrive\\ドキュメント\\GitHub\\Portfolios\\Projects\\Pb5_Rainfall data analysis of TN\\2024_Data.csv\",index_col=0)\n",
    "    #df4 = pd.concat([df3,Search_Rain_Fall_Data ])\n",
    "    #df4.to_csv(r\"C:\\Users\\Arunprakash Babu\\OneDrive\\ドキュメント\\GitHub\\Portfolios\\Projects\\Pb5_Rainfall data analysis of TN\\2024_Data.csv\")\n",
    "driver.quit()  \n",
    "Search_Rain_Fall_Data = Search_Rain_Fall_Data.reset_index(drop=True)\n",
    "Search_Rain_Fall_Data.index.name = 'id'\n",
    "Search_Rain_Fall_Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "004580f5-a9b1-4894-942f-377d09297c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search_Rain_Fall_Data.to_csv(r\"C:\\Users\\Arunprakash Babu\\OneDrive\\ドキュメント\\GitHub\\Portfolios\\Projects\\Pb5_Rainfall data analysis of TN\\2024_Rainfall_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3ec10b-fff7-41c7-94a8-75f47da95cab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
